# -*- coding: utf-8 -*-
"""postProcessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mtGzulFmHvZZocUbTZye2CdloPucC3A-

**Main Libraries**
"""

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

# Numerical libraries
import pandas as pd
import numpy as np

# Visualization
import matplotlib.pyplot as plt

# Statistics and Machine Learning
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import plot_confusion_matrix
from sklearn.metrics import plot_roc_curve
from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, classification_report

"""**Loading Data**"""

df_out = pd.read_csv('LSTM_output.csv')
df_out = df_out[['rollRate','pitchRate','yawRate','anomaly27']].tail(int(0.25*len(df_out)))
df_out

df_out.anomaly27.value_counts()

df_out.hist()

"""**X, y matrices**"""

X = df_out[['rollRate','pitchRate','yawRate']]
y = df_out[['anomaly27']]

print(X.head(),'\n\n',y.head())

X_train,X_test,\
y_train,y_test = train_test_split(X,y,test_size=0.05,random_state=42)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

"""**Classifier**"""

# Hyperparameters tunning
hyperparameters = {
    "learning_rate":[0.05, 0.1, 0.2, 0.5, 0.9],
    "n_estimators":[20, 50, 100, 200, 300, 500, 700, 1000],
    "max_depth":[3, 5, 10, 15, 20, 30],
    "min_samples_split":[2, 4, 7, 10],
    "min_samples_leaf":[1, 2, 3, 5, 8, 10],
    "min_impurity_decrease":[0., 0.2, 0.4, 0.5, 0.6, 0.8, 1.],
    "max_leaf_nodes":[5, 10, 20, 30, 50, 100, 300]
}

# Create a baseline model
model = GradientBoostingClassifier()

# Instantiate the params grid search model
randomized_search = RandomizedSearchCV(model, hyperparameters, random_state=42, n_iter=5, scoring=None,
                                       n_jobs=-1, refit=True, cv=5, verbose=True,return_train_score=True)

# Fit the grid search to the data
randomized_search.fit(X_train, y_train)

hyperparameters_tuning = randomized_search
print('Best Parameters = {}'.format(hyperparameters_tuning.best_params_))

classifier = GradientBoostingClassifier(n_estimators=500,min_samples_split=10,min_samples_leaf=10,
                                                           min_impurity_decrease=0.2,max_leaf_nodes=50,max_depth=100,
                                                           learning_rate=0.05,criterion='friedman_mse')
classifier = classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)
y_pred = pd.DataFrame({'anomalyFlag':list(y_pred)})
y_pred

f1 = round(f1_score(y_test, y_pred, average='macro')*100, 2)
accuracy = round(accuracy_score(y_test, y_pred)*100,2)
precision = round(precision_score(y_test, y_pred)*100,2)
recall = round(recall_score(y_test, y_pred)*100,2)

print(f"F1 Score: {f1}%")
print(f"Accuracy Score: {accuracy}%")
print(f"Precision Score: {precision}%")
print(f"Recall Score: {recall}%")

plot_confusion_matrix(classifier, X_test, y_test, values_format='d')  
plt.grid(False)
plt.show()

plot_roc_curve(classifier, X_test, y_test)  
plt.grid(True)
plt.show()

"""**Exporting the Model**"""

# saving the model (joblib)
import joblib
filename = 'anomalyDetector.joblib'
joblib.dump(classifier, filename)

# loading the model (joblib)
filename = 'anomalyDetector.joblib'
loaded_model = joblib.load(filename)
loaded_model

# Example of data to take as input to the model
X.iloc[5]

X.iloc[[5]].values #input values

model_input = X.iloc[[5]].values
model_output = loaded_model.predict(model_input)
model_output